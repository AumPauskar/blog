<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Big data and hadoop ecosystem | Aum's blogging site</title>
<meta name=keywords content><meta name=description content="Big data Just data Structured data: data that has a defined length and format for each record. It&rsquo;s stored in a fixed format such as a relational database or spreadsheet. It&rsquo;s easy to search and analyze. It&rsquo;s used for transactional data. Unstructured data: data that has an unknown length and format. It&rsquo;s stored in a free format such as a text file. It&rsquo;s difficult to search and analyze. It&rsquo;s used for non-transactional data."><meta name=author content="Aum Pauskar"><link rel=canonical href=http://aumpauskar.site/blog/posts/dbms/big_data_hadoop/><link crossorigin=anonymous href=/blog/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U+6hYRq/Ez/nm5vg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/blog/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=http://aumpauskar.site/blog/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://aumpauskar.site/blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://aumpauskar.site/blog/favicon-32x32.png><link rel=apple-touch-icon href=http://aumpauskar.site/blog/apple-touch-icon.png><link rel=mask-icon href=http://aumpauskar.site/blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-EV8NVH4QG5"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-EV8NVH4QG5",{anonymize_ip:!1})}</script><meta property="og:title" content="Big data and hadoop ecosystem"><meta property="og:description" content="Big data Just data Structured data: data that has a defined length and format for each record. It&rsquo;s stored in a fixed format such as a relational database or spreadsheet. It&rsquo;s easy to search and analyze. It&rsquo;s used for transactional data. Unstructured data: data that has an unknown length and format. It&rsquo;s stored in a free format such as a text file. It&rsquo;s difficult to search and analyze. It&rsquo;s used for non-transactional data."><meta property="og:type" content="article"><meta property="og:url" content="http://aumpauskar.site/blog/posts/dbms/big_data_hadoop/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-12-05T12:17:46+05:30"><meta property="article:modified_time" content="2023-12-05T12:17:46+05:30"><meta property="og:site_name" content="Aum's blogging site"><meta name=twitter:card content="summary"><meta name=twitter:title content="Big data and hadoop ecosystem"><meta name=twitter:description content="Big data Just data Structured data: data that has a defined length and format for each record. It&rsquo;s stored in a fixed format such as a relational database or spreadsheet. It&rsquo;s easy to search and analyze. It&rsquo;s used for transactional data. Unstructured data: data that has an unknown length and format. It&rsquo;s stored in a free format such as a text file. It&rsquo;s difficult to search and analyze. It&rsquo;s used for non-transactional data."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://aumpauskar.site/blog/posts/"},{"@type":"ListItem","position":2,"name":"Big data and hadoop ecosystem","item":"http://aumpauskar.site/blog/posts/dbms/big_data_hadoop/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Big data and hadoop ecosystem","name":"Big data and hadoop ecosystem","description":"Big data Just data Structured data: data that has a defined length and format for each record. It\u0026rsquo;s stored in a fixed format such as a relational database or spreadsheet. It\u0026rsquo;s easy to search and analyze. It\u0026rsquo;s used for transactional data. Unstructured data: data that has an unknown length and format. It\u0026rsquo;s stored in a free format such as a text file. It\u0026rsquo;s difficult to search and analyze. It\u0026rsquo;s used for non-transactional data.","keywords":[],"articleBody":"Big data Just data Structured data: data that has a defined length and format for each record. It’s stored in a fixed format such as a relational database or spreadsheet. It’s easy to search and analyze. It’s used for transactional data. Unstructured data: data that has an unknown length and format. It’s stored in a free format such as a text file. It’s difficult to search and analyze. It’s used for non-transactional data. Semi-structured data: data that has a defined length and format for each record but doesn’t conform to the structure of a relational database. It’s stored in a semi-structured format such as XML or JSON. It’s easy to search and analyze. It’s used for non-transactional data. Types of data analysis descriptive: what happened? diagnostic: why did it happen? predictive: what will happen? prescriptive: how can we make it happen? Data management software Hadoop Hadoop is a framework for distributed storage and processing of large data sets using the MapReduce programming model. It consists of a distributed file system (HDFS) and a distributed processing framework (MapReduce). It’s written in Java and is open source. It’s designed to scale up from single servers to thousands of machines, each offering local computation and storage. Rather than rely on hardware to deliver high-availability, the library itself is designed to detect and handle failures at the application layer, so delivering a highly-available service on top of a cluster of computers, each of which may be prone to failures. Its use cases include data lake, data warehouse, data hub, data science, and data engineering. It’s used by Facebook, Yahoo, LinkedIn, eBay, and Twitter. It’s core components are HDFS, YARN, and MapReduce.\nGoals\nHigh scalability and availability Fault tolerance Low cost High throughput Disadvantages\nIt’s not suitable for real-time processing of data It’s not suitable for processing small data sets It’s not suitable for processing unstructured data It’s not suitable for processing data that requires multiple iterations Distributed processing: processing of data sets across multiple computers in a cluster. It’s used for parallel processing of large data sets. It’s used for batch processing of data sets. It’s used for processing of unstructured data sets. It’s used for processing of data sets that require multiple iterations. It’s used for processing of data sets that require real-time processing.\nApache hardoop ecosystem\nHDFS: distributed file system YARN: resource management platform MapReduce: distributed processing framework Hive: data warehouse Pig: data flow language HBase: NoSQL database ZooKeeper: distributed coordination service Sqoop: data transfer tool Flume: data collection tool Oozie: workflow scheduler Spark: distributed processing framework HDFS HDFS is a distributed file system that provides high-throughput access to application data. It’s suitable for applications that have large data sets. It’s designed to run on commodity hardware. It’s highly fault-tolerant and is designed to be deployed on low-cost hardware. It provides high throughput access to application data and is suitable for applications that have large data sets. It relaxes a few POSIX requirements to enable streaming access to file system data. It’s written in Java and is open source. It’s used by Facebook, Yahoo, LinkedIn, eBay, and Twitter. It’s core components are NameNode, DataNode, and Secondary NameNode. It’s core components are NameNode, DataNode, and Secondary NameNode.\nFeatures of HDFS High throughput Fault tolerance Horizontal scalability High availability Data locality Data integrity Data compression Data access HDFS namenode HDFS namenode: Namenode is a centerpiece of HDFS. It keeps the directory tree of all files in the file system, and tracks where across the cluster the file data is kept. It does not store the data of these files itself. The namenode is a single point of failure for the HDFS cluster.\nFSI: file system image. It’s a file that contains the metadata of the HDFS. It’s stored in the namenode.\nedit log: It’s a file that contains the changes made to the FSI. It’s stored in the namenode.\nFunctions of the namenode\nIt manages the file system namespace. It regulates client’s access to files. It executes file system operations such as renaming, closing, and opening files and directories. It maps data blocks to data nodes. It manages the replication of data blocks. It executes periodic checkpoints of the file system metadata. Datanode: It’s a slave node that stores the actual data in HDFS. It’s responsible for serving read and write requests from the file system’s clients.\nFunctions of datanode:\nIt stores data in the local file system. It sends heartbeats and block reports to the namenode. It executes operations such as block creation, deletion, and replication as instructed by the namenode. It serves read and write requests from the file system’s clients. It performs block creation, deletion, and replication upon instruction from the namenode. (File) Blocks: It’s the smallest unit of data that can be stored or retrieved from a storage device. It’s a sequence of bytes with a maximum size of 128 MB in hadoop2.x (64MB in 1.x). It’s stored in the datanode.\nAdvantages of blocks\nIt’s easy to manage. It’s easy to replicate. It’s easy to distribute. It’s easy to process. Rack: It’s a collection of 30 or 40 machines that are physically stored together. It’s used to improve the network performance of the HDFS. It’s used to improve the fault tolerance of the HDFS.\nHDFS read write operations Read operation\nThe client sends a read request to the namenode. The namenode sends the metadata of the file to the client. The client sends a read request to the datanode. The datanode sends the data block to the client. The client reads the data block. Write operation\nThe client sends a write request to the namenode. The namenode sends the metadata of the file to the client. The client sends a write request to the datanode. The datanode sends an acknowledgement to the client. The client sends the data block to the datanode. The datanode sends an acknowledgement to the client. The client sends a write request to the namenode. The namenode sends an acknowledgement to the client. HDFS CLI It can be managed by a command line interface (CLI) or a web UI. The CLI is used for file operations, cluster maintenance, and data transfer. The web UI is used for monitoring and managing the cluster. It’s core components are NameNode, DataNode, and Secondary NameNode.\nSome of its basic commands are:\nhadoop fs -ls /: list the contents of the root directory hadoop fs -ls /user: list the contents of the user directory hadoop fs -mkdir /user/hadoop: create a directory named hadoop in the user directory hadoop fs -put /home/hadoop/file.txt /user/hadoop: copy the file.txt file from the local file system to the HDFS hadoop fs -get /user/hadoop/file.txt /home/hadoop: copy the file.txt file from the HDFS to the local file system hadoop fs -cat /user/hadoop/file.txt: display the contents of the file.txt file hadoop fs -rm /user/hadoop/file.txt: delete the file.txt file hadoop fs -rm -r /user/hadoop: delete the hadoop directory hdfs fsck /: check the HDFS for errors hdfs dfs -ls /: list the contents of the root directory hdfs dfs -mkdir : create a directory hdfs dfs -cat : display the contents of a file hdfs dfs -rm : delete a file hdfs dfs -rm -r : delete a directory hdfs dfs -count : count the number of directories, files, and bytes under the paths that match the specified file pattern hdfs dfs -cp : copy files from the source to the destination hdfs dfs -mv : move files from the source to the destination hdfs dfs -get : copy files from the HDFS to the local file system sbin/start-all.sh: start all the hardoop daemons sbin/stop-all.sh: stop all the hardoop daemons jps: list the java processes running on the machine YARN YARN stands for Yet Another Resource Negotiator. It’s a resource management platform responsible for managing computing resources in clusters and using them for scheduling of users’ applications. It’s the architectural center of Hadoop that allows multiple data processing engines such as interactive SQL, real-time streaming, data science, and batch processing to handle data stored in a single platform, unlocking an entirely new approach to analytics. It’s written in Java and is open source. It’s used by Facebook, Yahoo, LinkedIn, eBay, and Twitter. It’s core components are ResourceManager, NodeManager, and ApplicationMaster.\n","wordCount":"1373","inLanguage":"en","datePublished":"2023-12-05T12:17:46+05:30","dateModified":"2023-12-05T12:17:46+05:30","author":{"@type":"Person","name":"Aum Pauskar"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://aumpauskar.site/blog/posts/dbms/big_data_hadoop/"},"publisher":{"@type":"Organization","name":"Aum's blogging site","logo":{"@type":"ImageObject","url":"http://aumpauskar.site/blog/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://aumpauskar.site/blog/ accesskey=h title="Aum's blogging site (Alt + H)">Aum's blogging site</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://aumpauskar.site/blog/>Home</a>&nbsp;»&nbsp;<a href=http://aumpauskar.site/blog/posts/>Posts</a></div><h1 class=post-title>Big data and hadoop ecosystem</h1><div class=post-meta><span title='2023-12-05 12:17:46 +0530 IST'>December 5, 2023</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1373 words&nbsp;·&nbsp;Aum Pauskar</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#just-data>Just data</a></li><li><a href=#data-management-software>Data management software</a><ul><li><a href=#hadoop>Hadoop</a></li><li><a href=#yarn>YARN</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h1 id=big-data>Big data<a hidden class=anchor aria-hidden=true href=#big-data>#</a></h1><h2 id=just-data>Just data<a hidden class=anchor aria-hidden=true href=#just-data>#</a></h2><ul><li>Structured data: data that has a defined length and format for each record. It&rsquo;s stored in a fixed format such as a relational database or spreadsheet. It&rsquo;s easy to search and analyze. It&rsquo;s used for transactional data.</li><li>Unstructured data: data that has an unknown length and format. It&rsquo;s stored in a free format such as a text file. It&rsquo;s difficult to search and analyze. It&rsquo;s used for non-transactional data.</li><li>Semi-structured data: data that has a defined length and format for each record but doesn&rsquo;t conform to the structure of a relational database. It&rsquo;s stored in a semi-structured format such as XML or JSON. It&rsquo;s easy to search and analyze. It&rsquo;s used for non-transactional data.</li><li>Types of data analysis<ol><li>descriptive: what happened?</li><li>diagnostic: why did it happen?</li><li>predictive: what will happen?</li><li>prescriptive: how can we make it happen?</li></ol></li></ul><h2 id=data-management-software>Data management software<a hidden class=anchor aria-hidden=true href=#data-management-software>#</a></h2><h3 id=hadoop>Hadoop<a hidden class=anchor aria-hidden=true href=#hadoop>#</a></h3><p>Hadoop is a framework for distributed storage and processing of large data sets using the MapReduce programming model. It consists of a distributed file system (HDFS) and a distributed processing framework (MapReduce). It&rsquo;s written in Java and is open source. It&rsquo;s designed to scale up from single servers to thousands of machines, each offering local computation and storage. Rather than rely on hardware to deliver high-availability, the library itself is designed to detect and handle failures at the application layer, so delivering a highly-available service on top of a cluster of computers, each of which may be prone to failures. Its use cases include data lake, data warehouse, data hub, data science, and data engineering. It&rsquo;s used by Facebook, Yahoo, LinkedIn, eBay, and Twitter. It&rsquo;s core components are HDFS, YARN, and MapReduce.</p><ul><li><p>Goals</p><ul><li>High scalability and availability</li><li>Fault tolerance</li><li>Low cost</li><li>High throughput</li></ul></li><li><p>Disadvantages</p><ul><li>It&rsquo;s not suitable for real-time processing of data</li><li>It&rsquo;s not suitable for processing small data sets</li><li>It&rsquo;s not suitable for processing unstructured data</li><li>It&rsquo;s not suitable for processing data that requires multiple iterations</li></ul></li><li><p>Distributed processing: processing of data sets across multiple computers in a cluster. It&rsquo;s used for parallel processing of large data sets. It&rsquo;s used for batch processing of data sets. It&rsquo;s used for processing of unstructured data sets. It&rsquo;s used for processing of data sets that require multiple iterations. It&rsquo;s used for processing of data sets that require real-time processing.</p></li><li><p>Apache hardoop ecosystem</p><ul><li>HDFS: distributed file system</li><li>YARN: resource management platform</li><li>MapReduce: distributed processing framework</li><li>Hive: data warehouse</li><li>Pig: data flow language</li><li>HBase: NoSQL database</li><li>ZooKeeper: distributed coordination service</li><li>Sqoop: data transfer tool</li><li>Flume: data collection tool</li><li>Oozie: workflow scheduler</li><li>Spark: distributed processing framework</li></ul></li></ul><h4 id=hdfs>HDFS<a hidden class=anchor aria-hidden=true href=#hdfs>#</a></h4><p>HDFS is a distributed file system that provides high-throughput access to application data. It&rsquo;s suitable for applications that have large data sets. It&rsquo;s designed to run on commodity hardware. It&rsquo;s highly fault-tolerant and is designed to be deployed on low-cost hardware. It provides high throughput access to application data and is suitable for applications that have large data sets. It relaxes a few POSIX requirements to enable streaming access to file system data. It&rsquo;s written in Java and is open source. It&rsquo;s used by Facebook, Yahoo, LinkedIn, eBay, and Twitter. It&rsquo;s core components are NameNode, DataNode, and Secondary NameNode. It&rsquo;s core components are NameNode, DataNode, and Secondary NameNode.</p><ul><li>Features of HDFS<ul><li>High throughput</li><li>Fault tolerance</li><li>Horizontal scalability</li><li>High availability</li><li>Data locality</li><li>Data integrity</li><li>Data compression</li><li>Data access</li></ul></li></ul><h4 id=hdfs-namenode>HDFS namenode<a hidden class=anchor aria-hidden=true href=#hdfs-namenode>#</a></h4><ul><li><p>HDFS namenode: Namenode is a centerpiece of HDFS. It keeps the directory tree of all files in the file system, and tracks where across the cluster the file data is kept. It does not store the data of these files itself. The namenode is a single point of failure for the HDFS cluster.</p></li><li><p>FSI: file system image. It&rsquo;s a file that contains the metadata of the HDFS. It&rsquo;s stored in the namenode.</p></li><li><p>edit log: It&rsquo;s a file that contains the changes made to the FSI. It&rsquo;s stored in the namenode.</p></li><li><p>Functions of the namenode</p><ul><li>It manages the file system namespace.</li><li>It regulates client&rsquo;s access to files.</li><li>It executes file system operations such as renaming, closing, and opening files and directories.</li><li>It maps data blocks to data nodes.</li><li>It manages the replication of data blocks.</li><li>It executes periodic checkpoints of the file system metadata.</li></ul></li><li><p>Datanode: It&rsquo;s a slave node that stores the actual data in HDFS. It&rsquo;s responsible for serving read and write requests from the file system&rsquo;s clients.</p></li><li><p>Functions of datanode:</p><ul><li>It stores data in the local file system.</li><li>It sends heartbeats and block reports to the namenode.</li><li>It executes operations such as block creation, deletion, and replication as instructed by the namenode.</li><li>It serves read and write requests from the file system&rsquo;s clients.</li><li>It performs block creation, deletion, and replication upon instruction from the namenode.</li></ul></li><li><p>(File) Blocks: It&rsquo;s the smallest unit of data that can be stored or retrieved from a storage device. It&rsquo;s a sequence of bytes with a maximum size of 128 MB in hadoop2.x (64MB in 1.x). It&rsquo;s stored in the datanode.</p></li><li><p>Advantages of blocks</p><ul><li>It&rsquo;s easy to manage.</li><li>It&rsquo;s easy to replicate.</li><li>It&rsquo;s easy to distribute.</li><li>It&rsquo;s easy to process.</li></ul></li><li><p>Rack: It&rsquo;s a collection of 30 or 40 machines that are physically stored together. It&rsquo;s used to improve the network performance of the HDFS. It&rsquo;s used to improve the fault tolerance of the HDFS.</p></li></ul><h4 id=hdfs-read-write-operations>HDFS read write operations<a hidden class=anchor aria-hidden=true href=#hdfs-read-write-operations>#</a></h4><ul><li><p>Read operation</p><ol><li>The client sends a read request to the namenode.</li><li>The namenode sends the metadata of the file to the client.</li><li>The client sends a read request to the datanode.</li><li>The datanode sends the data block to the client.</li><li>The client reads the data block.</li></ol></li><li><p>Write operation</p><ol><li>The client sends a write request to the namenode.</li><li>The namenode sends the metadata of the file to the client.</li><li>The client sends a write request to the datanode.</li><li>The datanode sends an acknowledgement to the client.</li><li>The client sends the data block to the datanode.</li><li>The datanode sends an acknowledgement to the client.</li><li>The client sends a write request to the namenode.</li><li>The namenode sends an acknowledgement to the client.</li></ol></li></ul><h4 id=hdfs-cli>HDFS CLI<a hidden class=anchor aria-hidden=true href=#hdfs-cli>#</a></h4><p>It can be managed by a command line interface (CLI) or a web UI. The CLI is used for file operations, cluster maintenance, and data transfer. The web UI is used for monitoring and managing the cluster. It&rsquo;s core components are NameNode, DataNode, and Secondary NameNode.</p><p>Some of its basic commands are:</p><ul><li><code>hadoop fs -ls /</code>: list the contents of the root directory</li><li><code>hadoop fs -ls /user</code>: list the contents of the user directory</li><li><code>hadoop fs -mkdir /user/hadoop</code>: create a directory named hadoop in the user directory</li><li><code>hadoop fs -put /home/hadoop/file.txt /user/hadoop</code>: copy the file.txt file from the local file system to the HDFS</li><li><code>hadoop fs -get /user/hadoop/file.txt /home/hadoop</code>: copy the file.txt file from the HDFS to the local file system</li><li><code>hadoop fs -cat /user/hadoop/file.txt</code>: display the contents of the file.txt file</li><li><code>hadoop fs -rm /user/hadoop/file.txt</code>: delete the file.txt file</li><li><code>hadoop fs -rm -r /user/hadoop</code>: delete the hadoop directory</li><li><code>hdfs fsck /</code>: check the HDFS for errors</li><li><code>hdfs dfs -ls /</code>: list the contents of the root directory</li><li><code>hdfs dfs -mkdir &lt;dirname></code>: create a directory</li><li><code>hdfs dfs -cat &lt;filename></code>: display the contents of a file</li><li><code>hdfs dfs -rm &lt;filename></code>: delete a file</li><li><code>hdfs dfs -rm -r &lt;dirname></code>: delete a directory</li><li><code>hdfs dfs -count &lt;file/dir></code>: count the number of directories, files, and bytes under the paths that match the specified file pattern</li><li><code>hdfs dfs -cp &lt;source> &lt;destination></code>: copy files from the source to the destination</li><li><code>hdfs dfs -mv &lt;source> &lt;destination></code>: move files from the source to the destination</li><li><code>hdfs dfs -get &lt;source> &lt;destination></code>: copy files from the HDFS to the local file system</li><li><code>sbin/start-all.sh</code>: start all the hardoop daemons</li><li><code>sbin/stop-all.sh</code>: stop all the hardoop daemons</li><li><code>jps</code>: list the java processes running on the machine</li></ul><h3 id=yarn>YARN<a hidden class=anchor aria-hidden=true href=#yarn>#</a></h3><p>YARN stands for Yet Another Resource Negotiator. It&rsquo;s a resource management platform responsible for managing computing resources in clusters and using them for scheduling of users&rsquo; applications. It&rsquo;s the architectural center of Hadoop that allows multiple data processing engines such as interactive SQL, real-time streaming, data science, and batch processing to handle data stored in a single platform, unlocking an entirely new approach to analytics. It&rsquo;s written in Java and is open source. It&rsquo;s used by Facebook, Yahoo, LinkedIn, eBay, and Twitter. It&rsquo;s core components are ResourceManager, NodeManager, and ApplicationMaster.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=http://aumpauskar.site/blog/posts/ml/image_analysis_theory/><span class=title>« Prev</span><br><span>Image analysis theory</span>
</a><a class=next href=http://aumpauskar.site/blog/posts/ml/image_analysis/><span class=title>Next »</span><br><span>Image analysis with pytorch</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Big data and hadoop ecosystem on x" href="https://x.com/intent/tweet/?text=Big%20data%20and%20hadoop%20ecosystem&amp;url=http%3a%2f%2faumpauskar.site%2fblog%2fposts%2fdbms%2fbig_data_hadoop%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Big data and hadoop ecosystem on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2faumpauskar.site%2fblog%2fposts%2fdbms%2fbig_data_hadoop%2f&amp;title=Big%20data%20and%20hadoop%20ecosystem&amp;summary=Big%20data%20and%20hadoop%20ecosystem&amp;source=http%3a%2f%2faumpauskar.site%2fblog%2fposts%2fdbms%2fbig_data_hadoop%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Big data and hadoop ecosystem on reddit" href="https://reddit.com/submit?url=http%3a%2f%2faumpauskar.site%2fblog%2fposts%2fdbms%2fbig_data_hadoop%2f&title=Big%20data%20and%20hadoop%20ecosystem"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Big data and hadoop ecosystem on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2faumpauskar.site%2fblog%2fposts%2fdbms%2fbig_data_hadoop%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Big data and hadoop ecosystem on whatsapp" href="https://api.whatsapp.com/send?text=Big%20data%20and%20hadoop%20ecosystem%20-%20http%3a%2f%2faumpauskar.site%2fblog%2fposts%2fdbms%2fbig_data_hadoop%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Big data and hadoop ecosystem on telegram" href="https://telegram.me/share/url?text=Big%20data%20and%20hadoop%20ecosystem&amp;url=http%3a%2f%2faumpauskar.site%2fblog%2fposts%2fdbms%2fbig_data_hadoop%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Big data and hadoop ecosystem on ycombinator" href="https://news.ycombinator.com/submitlink?t=Big%20data%20and%20hadoop%20ecosystem&u=http%3a%2f%2faumpauskar.site%2fblog%2fposts%2fdbms%2fbig_data_hadoop%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=http://aumpauskar.site/blog/>Aum's blogging site</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>